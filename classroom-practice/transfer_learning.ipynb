{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOU063E4DPtxDWT5DxXPCcy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinothalagupandi/mlflow-practise/blob/master/classroom-practice/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --header 'Host: storage.googleapis.com' --user-agent 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/116.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --referer 'https://www.kaggle.com/' --header 'Upgrade-Insecure-Requests: 1' --header 'Sec-Fetch-Dest: document' --header 'Sec-Fetch-Mode: navigate' --header 'Sec-Fetch-Site: cross-site' --header 'Sec-Fetch-User: ?1' 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/10338/862042/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1707672971&Signature=Y9M82nFK7KOEYvwG3M229IiD7K07YqETpjqOGrDh2MnJcJFCrGiYcDjOx9flDj8Wj72GBI4OqYMyadyn0FvR5kr5YVxe2k%2BONJyE5PkF%2B%2FtuttqaxPD4UxnomYtZL8xuyO6ve%2BiSVO5%2FB4l6HtoUz%2FKXSNbZ%2BRRJFgBHA4jfZe9oxf0VxvR6YtOdGLe3iHv9J%2FlsymZxeS4yGVLSajupcAHtHgo%2F%2B%2FnuPp1OSWMZhym%2BnqVUeJ1ait9DAwv4Fg4cnqUdrpsUuNmCitwaZe97wefu0KLiEoqyGFx3FcWPzyhsu4pl%2F55hZFD2GUMNXMfG%2BD6VOE3F4HvIccgUf1EkxA%3D%3D&response-content-disposition=attachment%3B+filename%3Drsna-pneumonia-detection-challenge.zip' --output-document 'rsna-pneumonia-detection-challenge.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6J0bXMTvQkE",
        "outputId": "e93d1676-a8bd-45f7-8c72-043d180b8147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-08 18:47:44--  https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/10338/862042/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1707672971&Signature=Y9M82nFK7KOEYvwG3M229IiD7K07YqETpjqOGrDh2MnJcJFCrGiYcDjOx9flDj8Wj72GBI4OqYMyadyn0FvR5kr5YVxe2k%2BONJyE5PkF%2B%2FtuttqaxPD4UxnomYtZL8xuyO6ve%2BiSVO5%2FB4l6HtoUz%2FKXSNbZ%2BRRJFgBHA4jfZe9oxf0VxvR6YtOdGLe3iHv9J%2FlsymZxeS4yGVLSajupcAHtHgo%2F%2B%2FnuPp1OSWMZhym%2BnqVUeJ1ait9DAwv4Fg4cnqUdrpsUuNmCitwaZe97wefu0KLiEoqyGFx3FcWPzyhsu4pl%2F55hZFD2GUMNXMfG%2BD6VOE3F4HvIccgUf1EkxA%3D%3D&response-content-disposition=attachment%3B+filename%3Drsna-pneumonia-detection-challenge.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.68.207, 64.233.170.207, 142.251.175.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.68.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3932287530 (3.7G) [application/zip]\n",
            "Saving to: ‘rsna-pneumonia-detection-challenge.zip’\n",
            "\n",
            "              rsna-  51%[=========>          ]   1.89G  21.3MB/s    eta 88s    "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/rsna-pneumonia-detection-challenge.zip"
      ],
      "metadata": {
        "id": "KL7RO2xrur0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chest X ray train test val data exploration"
      ],
      "metadata": {
        "id": "Tr7ULYYhvrLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv(\"/content/stage_2_train_labels.csv\")\n",
        "\n",
        "# Keep only the \"patientId\" and \"Target\" columns\n",
        "df = df[[\"patientId\", \"Target\"]]\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "zrAfM0NOvuk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = df.drop_duplicates()\n",
        "df = df[df.notnull().all(axis=1)]\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "J_Dcg5LM38z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# Get the path to the train images directory\n",
        "train_images_dir = \"/content/stage_2_train_images\"\n",
        "\n",
        "# List the files in the directory\n",
        "files = os.listdir(train_images_dir)\n",
        "\n",
        "# Print the files\n",
        "print(files[:10])\n"
      ],
      "metadata": {
        "id": "a77XaAyL0Mas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df),len(files)"
      ],
      "metadata": {
        "id": "fcafWP674LgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"0004cfab-14fd-4e49-80ba-63a80b6bddd6.dcm\" in files"
      ],
      "metadata": {
        "id": "s74ey2Gq0xKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in list(df[\"patientId\"]):\n",
        "  if f\"{ids}.dcm\" not in files:\n",
        "    print(f\"{id} is not heree\")"
      ],
      "metadata": {
        "id": "XmueRHZi07PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the DataFrame into train and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "# Print the shapes of the train and validation DataFrames\n",
        "print(f\"Train DataFrame shape: {train_df.shape}\")\n",
        "print(f\"Validation DataFrame shape: {val_df.shape}\")\n"
      ],
      "metadata": {
        "id": "UCN4iRZq1SMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydicom"
      ],
      "metadata": {
        "id": "aFvSbvLJ2giS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import pydicom\n",
        "def read_dicom_image(path,label):\n",
        "    img_raw = tf.io.read_file(path)\n",
        "    image = tfio.image.decode_dicom_image(img_raw, dtype=tf.uint16)\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    image = tf.image.grayscale_to_rgb(image,name=None)\n",
        "    label = tf.reshape(label,[1])\n",
        "    return image,label\n",
        "\n",
        "def create_dataset(df, image_dir):\n",
        "    paths = [os.path.join(image_dir, f\"{id}.dcm\") for id in df[\"patientId\"]]\n",
        "    labels = list(df[\"Target\"].values)\n",
        "    paths=tf.constant(paths)\n",
        "    labels = tf.constant(labels)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
        "    dataset = dataset.map(read_dicom_image)\n",
        "    return dataset\n",
        "train_images_dir = \"/content/stage_2_train_images\"\n",
        "\n",
        "train_dataset = create_dataset(train_df, train_images_dir,batch_size=64)\n",
        "val_dataset = create_dataset(val_df, train_images_dir,64)"
      ],
      "metadata": {
        "id": "kYNhL9Wc1laU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in train_dataset:\n",
        "  print(y)\n",
        "  # print(x.shape,y.shape)\n",
        "  # print(x.numpy(),y.numpy())\n",
        "  break"
      ],
      "metadata": {
        "id": "9yfBm3OE45kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Hpmz1X1z88tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the first image and label from the train dataset\n",
        "image, label = next(iter(train_dataset))\n",
        "\n",
        "# Print the image shape and label\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "print(f\"Label: {label}\")\n",
        "\n",
        "# Plot the image\n",
        "plt.imshow(image[0])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0TH5k4kA9OsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ],
      "metadata": {
        "id": "MshpXLE--iiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "# Load the ResNet50 model with pre-trained weights\n",
        "conv_base = ResNet50(weights=\"imagenet\",include_top=False,input_shape=(224, 224, 3))\n",
        "conv_base.trainable = False\n",
        "# Print the model summary\n",
        "# conv_base.summary()\n"
      ],
      "metadata": {
        "id": "63vsFmpe9xHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = keras.applications.resnet50.preprocess_input(image)\n",
        "x.shape\n"
      ],
      "metadata": {
        "id": "crh3vqRL-1ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2o4Wxigz-7sf"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs= keras.Input(shape=(224,224, 3))\n",
        "x = keras.applications.resnet50.preprocess_input(inputs)\n",
        "x = conv_base(inputs)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "Nh-3ddK83SME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "mvwj2whPBRjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"rsna_resnet50.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "sL6-gYEH_Tpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Tensor(\"args_0:0\", shape=(), dtype=string)  in dataset\n",
        "\n",
        "paths = tf.constant([\"/content/stage_2_train_images/0004cfab-14fd-4e49-80ba-63a80b6bddd6.dcm\", \"/content/stage_2_train_images/0031985d-9d1a-4b83-b833-f818b32975b8.dcm\"])\n",
        "labels = tf.constant([1, 0])\n",
        "dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
        "dataset = dataset.map(lambda x, y: (read_dicom_image(x), y))\n",
        "\n",
        "for x,y in dataset:\n",
        "  print(x.shape,y)\n"
      ],
      "metadata": {
        "id": "YVcZd0o93d15"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}